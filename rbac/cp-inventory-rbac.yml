all:
  vars:
    ansible_connection: ssh
    ansible_user: ubuntu
    ansible_become: true
    ansible_ssh_private_key_file: ~/.ssh/purbon-ireland.pem

    sasl_plain_users:
      admin:
        principal: admin
        password: admin-secret
      client:
        principal: client
        password: client-secret
      kafka_connect:
        principal: kafka_connect
        password: kafka_connect-secret
      control_center:
        principal: control_center
        password: control_center-secret
      kafka_rest:
        principal: kafka_rest
        password: kafka_rest-secret
      ksql:
        principal: ksql
        password: ksql-secret
      schema_registry:
        principal: schema_registry
        password: schema_registry-secret
      mds:
        principal: mds
        password: mds-secret

    #### SASL Authentication Configuration ####
    ## By default there will be no SASL Authentication
    ## For SASL/PLAIN uncomment this line:
    # sasl_protocol: plain
    ## For SASL/SCRAM uncomment this line:
    # sasl_protocol: scram
    ## For SASL/GSSAPI uncomment this line and see Kerberos Configuration properties below
    # sasl_protocol: kerberos

    #### Kerberos Configuration ####
    ## Applicable when sasl_protocol is kerberos
    # kerberos_kafka_broker_primary: <Name of the primary set on the kafka brokers' principal eg. kafka>
    ## REQUIRED: Under each host set keytab file path and principal name, see below
    # kerberos_configure: <Boolean for ansible to install kerberos packages and configure this file: /etc/krb5.conf, defaults to true>
    # kerberos:
    #   realm: <KDC server realm eg. confluent.example.com>
    #   kdc_hostname: <hostname of machine with KDC running eg. ip-172-31-45-82.us-east-2.compute.internal>
    #   admin_hostname: <hostname of machine with KDC running eg. ip-172-31-45-82.us-east-2.compute.internal>

    #### TLS Configuration ####
    ## By default, data will NOT be encrypted. To turn on TLS encryption, uncomment this line
    # ssl_enabled: true
    ## By default, the components will be configured with One-Way TLS, to turn on TLS mutual auth, uncomment this line:
    # ssl_mutual_auth_enabled: true
    ## By default, the certs for this configuration will be self signed, to deploy custom certificates there are two options.
    ## Option 1: Custom Certs
    ## You will need to provide the path to the Certificate Authority Cert used to sign each hosts' certs
    ## As well as the signed certificate path and the key for that certificate for each host.
    ## These will need to be set for the correct host
    # ssl_custom_certs: true
    # ssl_ca_cert_filepath: "/tmp/certs/ca.crt"
    # ssl_signed_cert_filepath: "/tmp/certs/{{inventory_hostname}}-signed.crt"
    # ssl_key_filepath: "/tmp/certs/{{inventory_hostname}}-key.pem"
    ## Option 2: Custom Keystores and Truststores
    ## CP-Ansible can move keystores/truststores to their corresponding hosts and configure the components to use them. Set These vars
    # ssl_provided_keystore_and_truststore: true
    # ssl_keystore_filepath: "/tmp/certs/{{inventory_hostname}}-keystore.jks"
    # ssl_keystore_key_password: mystorepassword
    # ssl_keystore_store_password: mystorepassword
    # ssl_truststore_filepath: "/tmp/certs/truststore.jks"
    # ssl_truststore_password: truststorepass

    #### Monitoring Configuration ####
    ## Jolokia is enabled by default. The Jolokia jar gets pulled from the internet and enabled on all the components
    ## To disable, uncomment this line:
    # jolokia_enabled: false
    ## During setup, the hosts will download the jolokia agent jar from Maven. To update that jar download set this var
    # jolokia_jar_url: http://<inteneral-server>/jolokia-jvm-1.6.2-agent.jar
    ## JMX Exporter is disabled by default. When enabled, JMX Exporter jar will be pulled from the Internet and enabled on the broker *only*.
    ## To enable, uncomment this line:
    # jmxexporter_enabled: true
    ## To update that jar download set this var
    # jmxexporter_jar_url: http://<internal-server>/jmx_prometheus_javaagent-0.12.0.jar

    #### Custom Yum Repo File (Rhel/Centos) ####
    ## If you are using your own yum repo server to host the packages, in the case of an air-gapped environment,
    ## use the below variables to distribute a custom .repo file to the hosts and skip our repo setup.
    ## Note, your repo server must host all confluent packages
    # custom_yum_repofile: true
    # custom_yum_repofile_filepath: /tmp/my-repo.repo

    #### Custom Apt Repo File (Ubuntu/Debian) ####
    ## If you are using your own apt repo server to host the packages, in the case of an air-gapped environment,
    ## use the below variables to distribute a custom .repo file to the hosts and skip our repo setup.
    ## Note, your repo server must host all confluent packages
    # custom_apt_repo: true
    # custom_apt_repo_filepath: "/tmp/my-source.list"

    #### Confluent Server vs Confluent Kafka ####
    ## Confluent Server will be installed by default, to install confluent-kafka instead, uncomment the below
    confluent_server_enabled: true

    #### Schema Validation ####
    ## Schema Validation with the kafka configuration is disabled by default. To enable uncomment this line:
    ## Schema Validation only works with confluent_server_enabled: true
    # kafka_broker_schema_validation_enabled: true

    #### Fips Security ####
    ## To enable Fips for added security, uncomment the below line.
    ## Fips only works with ssl_enabled: true and confluent_server_enabled: true
    # fips_enabled: true

    #### Configuring Different Security on both Listeners ####
    ## CP-Ansible will configure two listeners on the broker: an internal listener for the broker to communicate and an external for the components and other clients.
    ## If you only need one listener uncomment this line:
    # kafka_broker_configure_additional_brokers: false
    ## By default both of these listeners will follow whatever you set for ssl_enabled and sasl_protocol.
    ## To configure different security settings on the internal and external listeners set the following variables:
    kafka_broker_custom_listeners:
       internal:
         name: INTERNAL
         port: 9091
         ssl_enabled: false
         ssl_mutual_auth_enabled: false
         sasl_protocol: scram
       external:
         name: EXTERNAL
         port: 9092
         ssl_enabled: false
         ssl_mutual_auth_enabled: false
         sasl_protocol: OAUTHBEARER
    ## You can even add additional listeners, make sure all variables are set
    #   client_listener:
    #     name: CLIENT
    #     port: 9093
    #     ssl_enabled: true
    #     ssl_mutual_auth_enabled: true
    #     sasl_protocol: scram

    ## To set custom properties for each service
    ## Find property options in the Confluent Documentation
    zookeeper:
      properties:
         dataDir: /var/lib/zookeeper
         initLimit: 6
         syncLimit: 3
    kafka_broker:
       properties:
         num.io.threads: 15
         super.users: User:admin;User:mds;User:professor
         confluent.schema.registry.url: 'http://ip-172-31-18-93.eu-west-1.compute.internal:8081'
         confluent.metadata.security.protocol: SASL_PLAINTEXT
         authorizer.class.name: io.confluent.kafka.security.authorizer.ConfluentServerAuthorizer
         listener.name.external.oauthbearer.sasl.server.callback.handler.class:  io.confluent.kafka.server.plugins.auth.token.TokenBearerValidatorCallbackHandler
         listener.name.external.oauthbearer.sasl.login.callback.handler.class:  io.confluent.kafka.server.plugins.auth.token.TokenBearerServerLoginCallbackHandler
         listener.name.external.oauthbearer.sasl.jaas.config: "org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required \ publicKeyPath=\"/tmp/conf/public.pem\";"
         confluent.metadata.bootstrap.servers: INTERNAL://{inventory_hostname}:9091
         confluent.metadata.sasl.mechanism: PLAIN
         confluent.metadata.sasl.jaas.config: org.apache.kafka.common.security.plain.PlainLoginModule required \  username="mds" \ password="mds-secret";
         confluent.metadata.topic.replication.factor: 3
         confluent.metadata.server.authentication.mehod: BEARER
         confluent.metadata.server.authentication.roles: '**'
         confluent.metadata.server.listeners: http://0.0.0.0:8090
         confluent.metadata.server.advertised.listeners: http://{inventory_hostname}:8090
         confluent.metadata.server.token.auth.enable: 'true'
         confluent.metadata.server.token.max.lifetime.ms: 3600000
         confluent.metadata.server.token.signature.algorithm: RS256
         confluent.metadata.server.token.key.path: /tmp/conf/keypair.pem
         confluent.metadata.server.token.public.key.path: /tmp/conf/public.pem
         confluent.authorizer.access.rule.providers: CONFLUENT,ZK_ACL
         confluent.authorizer.group.providers: RBAC
         ldap.java.naming.factory.initial: com.sun.jndi.ldap.LdapCtxFactory
         ldap.com.sun.jndi.ldap.read.timeout: 3000
         ldap.java.naming.provider.url: ldap://{ldap_host}:389
         ldap.java.naming.security.principal: cn=admin,dc=planetexpress,dc=com
         ldap.java.naming.security.credentials: GoodNewsEveryone
         ldap.java.naming.security.authentication: simple
         ldap.user.search.base: ou=people,dc=planetexpress,dc=com
         ldap.group.search.base: ou=people,dc=planetexpress,dc=com
         ldap.user.name.attribute: uid
         ldap.user.object.class: inetOrgPerson
         ldap.user.memberof.attribute: ou
         ldap.group.name.attribute: cn
         ldap.group.object.class: group

    # schema_registry:
    #   properties:
    #     key: val
    control_center:
       properties:
         rest.authentication.method: BEARER
         public.key.path: /tmp/conf/public.pem
         confluent.metadata.basic.auth.user.info: hermes:hermes
         confluent.metadata.bootstrap.server.urls: {% for listener in kafka_broker_listeners|dict2items %}{% if loop.index > 1%},{% endif %}{{ listener['value']['name'] }}://{{ listener['value']['hostname'] | default('') }}:{{ listener['value']['port'] }}{% endfor %}
         streams.security.protocol: SASL_PLAINTEXT
         streams.sasl.mechanism: OAUTHBEARER
         streams.sasl.login.callback.handler.class: io.confluent.kafka.clients.plugins.auth.token.TokenUserLoginCallbackHandler
         streams.sasl.jaas.config: org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required \ username="hermes" \ password="hermes" \ metadataServerUrls="http://ip-172-31-23-186.eu-west-1.compute.internal:8090";

    # kafka_connect:
    #   properties:
    #     key: val
    # kafka_rest:
    #   properties:
    #     key: val
    # ksql:
    #   properties:
    #     key: val

zookeeper:
  hosts:
    ip-172-31-25-137.eu-west-1.compute.internal:
      ## By default the first host will get zookeeper id=1, second gets id=2. Set zookeeper_id to customize
      # zookeeper_id: 2

      ## For kerberos sasl protocol, EACH host will need these two variables:
      # zookeeper_kerberos_keytab_path: <The path on ansible host to keytab file, eg. /tmp/keytabs/zookeeper-ip-172-31-34-246.us-east-2.compute.internal.keytab>
      # zookeeper_kerberos_principal: <The principal configured in kdc server, eg. zookeeper/ip-172-31-34-246.us-east-2.compute.internal@REALM.EXAMPLE.COM>
    ip-172-31-47-172.eu-west-1.compute.internal:
      # zookeeper_id: 3
    ip-172-31-12-234.eu-west-1.compute.internal:
      # zookeeper_id: 1
kafka_broker:
  hosts:
    ip-172-31-23-186.eu-west-1.compute.internal:
      ## By default the first host will get broker id=1, second gets id=2. Set broker_id to customize
      # broker_id: 3

      ## For kerberos sasl protocol, EACH host will need these two variables:
      # kafka_broker_kerberos_keytab_path: <The path on ansible host to keytab file, eg. /tmp/keytabs/ip-172-31-34-246.us-east-2.compute.internal>
      # kafka_broker_kerberos_principal: <The principal configured in kdc server, eg. kafka/ip-172-31-34-246.us-east-2.compute.internal@REALM.EXAMPLE.COM>
    ip-172-31-45-247.eu-west-1.compute.internal:
      # broker_id: 2
    ip-172-31-14-232.eu-west-1.compute.internal:
      # broker_id: 1
control_center:
  hosts:
    ip-172-31-26-46.eu-west-1.compute.internal:
      ## For kerberos sasl protocol, EACH host will need these two variables:
      # control_center_kerberos_keytab_path: <The path on ansible host to keytab file, eg. /tmp/keytabs/controlcenter-ip-172-31-37-15.us-east-2.compute.internal
      # control_center_kerberos_principal: The principal configured in kdc server ex: controlcenter/ip-172-31-37-15.us-east-2.compute.internal@REALM.EXAMPLE.COM>
